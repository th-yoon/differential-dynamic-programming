{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Dynamic Programming for Quadcopter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf{x} = [x, v_x, y, v_y, z, v_z, x_q, y_q, z_q, \\omega_x, \\omega_y, \\omega_z]^\\top \\in \\mathbb{R}^{12}$ be a state vector, where $x, y, z$ are x-axis, y-axis, z-axis positions, respectively.  \n",
    "$x_q, y_q, z_q$ are x-axis, y-axis, z-axis component quaternions, respectively.  \n",
    "$v_x, v_y, v_z$ represent velocities on each axis.  \n",
    "$\\omega_x, \\omega_y, \\omega_z$ are angular velocities around each axis.  \n",
    "\n",
    "Let $\\mathbf{u} = [p_0, p_1, p_2, p_3] \\in \\mathbb{R}^4$ be a control vector, where $p$ represents the command RPM for a rotor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "from safe_control_gym.envs.gym_pybullet_drones.quadrotor import Quadrotor\n",
    "from safe_control_gym.envs.gym_pybullet_drones.quadrotor_utils import QuadType, cmd2pwm, pwm2rpm\n",
    "from safe_control_gym.math_and_models.symbolic_systems import SymbolicModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_NUM_DRONES = 1\n",
    "DEFAULT_GUI = True\n",
    "DEFAULT_RECORD_VISION = False\n",
    "DEFAULT_PLOT = True\n",
    "DEFAULT_USER_DEBUG_GUI = True\n",
    "DEFAULT_OBSTACLES = True\n",
    "DEFAULT_SIMULATION_FREQ_HZ = 240 # pybullet frequency\n",
    "DEFAULT_CONTROL_FREQ_HZ = 60\n",
    "DEFAULT_DURATION_SEC = 10\n",
    "DEFAULT_OUTPUT_FOLDER = 'results'\n",
    "DEFAULT_COLAB = True\n",
    "\n",
    "#### Action vector ######## Thrust           X Torque             Y Torque             Z Torque\n",
    "# ACT_LOWER_BOUND = np.array([0.,              -self.MAX_XY_TORQUE, -self.MAX_XY_TORQUE, -self.MAX_Z_TORQUE])\n",
    "# ACT_UPPER_BOUND = np.array([self.MAX_THRUST, self.MAX_XY_TORQUE,  self.MAX_XY_TORQUE,  self.MAX_Z_TORQUE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotZ(psi):\n",
    "    '''Rotation matrix about Z axis following SDFormat http://sdformat.org/tutorials?tut=specify_pose&cat=specification&.\n",
    "\n",
    "    Args:\n",
    "    psi: Scalar rotation\n",
    "\n",
    "    Returns:\n",
    "    R: Rotation matrix\n",
    "    '''\n",
    "    R = jnp.array([[jnp.cos(psi), -jnp.sin(psi), 0.],\n",
    "                    [jnp.sin(psi),  jnp.cos(psi), 0.],\n",
    "                    [          0.,            0., 1.]], dtype=float)\n",
    "    return R\n",
    "\n",
    "\n",
    "def rotY(theta):\n",
    "    '''Rotation matrix about Y axis following SDFormat http://sdformat.org/tutorials?tut=specify_pose&cat=specification&.\n",
    "\n",
    "    Args:\n",
    "    theta: Scalar rotation\n",
    "\n",
    "    Returns:\n",
    "    R: Rotation matrix\n",
    "    '''\n",
    "    R = jnp.array([[ jnp.cos(theta), 0., jnp.sin(theta)],\n",
    "                    [             0., 1.,             0.],\n",
    "                    [-jnp.sin(theta), 0., jnp.cos(theta)]], dtype=float)\n",
    "    return R\n",
    "\n",
    "\n",
    "def rotX(phi):\n",
    "    '''Rotation matrix about X axis following SDFormat http://sdformat.org/tutorials?tut=specify_pose&cat=specification&.\n",
    "\n",
    "    Args:\n",
    "    phi: Scalar rotation\n",
    "\n",
    "    Returns:\n",
    "    R: Rotation matrix\n",
    "    '''\n",
    "    R = jnp.array([[ 1.,           0.,            0.],\n",
    "                    [ 0., jnp.cos(phi), -jnp.sin(phi)],\n",
    "                    [ 0., jnp.sin(phi),  jnp.cos(phi)]], dtype=float)\n",
    "    return R\n",
    "\n",
    "\n",
    "def rotXYZ(phi, theta, psi):\n",
    "    '''Rotation matrix from euller angles  following SDFormat http://sdformat.org/tutorials?tut=specify_pose&cat=specification&.\n",
    "    This represents the extrinsic X-Y-Z (or quivalently the intrinsic Z-Y-X (3-2-1)) euler angle rotation.\n",
    "\n",
    "    Args:\n",
    "    phi: roll (or rotation about X).\n",
    "    theta: pitch (or rotation about Y).\n",
    "    psi: yaw (or rotation about Z).\n",
    "\n",
    "    Returns:\n",
    "    R: Rotation matrix\n",
    "    '''\n",
    "    R = rotZ(psi) @ rotY(theta) @ rotX(phi)\n",
    "\n",
    "    return R\n",
    "\n",
    "def skew(vec):\n",
    "    return jnp.array([[0., -vec[2], vec[1]],\n",
    "                    [vec[2], 0., -vec[0]],\n",
    "                    [-vec[1], vec[0], 0.]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class to describe a cartpole system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quadcopter3D:\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_drones: int,\n",
    "                 use_gui: bool,\n",
    "                 record_video: bool,\n",
    "                 debug_gui: bool,\n",
    "                 simulation_freq: int,\n",
    "                 control_freq: int,\n",
    "                 duration: int,\n",
    "                 output_folder: str,\n",
    "                 use_colab: bool):\n",
    "        # ddp iteration\n",
    "        self.iteration = 10 \n",
    "        # the number of drones for simulation\n",
    "        self.n_drones = n_drones\n",
    "        self.control_freq = control_freq\n",
    "        # the number of dimensions for a single agent\n",
    "        u_dim = 4\n",
    "        x_dim = 12\n",
    "        # time horizon\n",
    "        self.T = duration\n",
    "        # control u to be optimized\n",
    "        self.u = jnp.ones((self.T, u_dim), dtype=float) # dim: T x u_dim\n",
    "        # state x to be optimized\n",
    "        self.x = jnp.zeros((self.T, x_dim), dtype=float) # dim: T x x_dim \n",
    "        #self.x = self.x.at[:, 2].set(jnp.pi * 2)\n",
    "        self.updated_x = jnp.zeros((self.T, x_dim), dtype=float) # dim: T x x_dim \n",
    "        #self.desired_terminal_state = jnp.array([0, 0, jnp.pi, 0], dtype=float)\n",
    "        # state x for test\n",
    "        self.test_x = jnp.zeros((self.T, x_dim), dtype=float) # dim: T x x_dim \n",
    "        self.test_updated_x = jnp.zeros((self.T, x_dim), dtype=float) # dim: T x x_dim \n",
    "\n",
    "        # gains to be optimized\n",
    "        self.k = jnp.zeros((self.T, u_dim), dtype=float) # dim: T x u_dim\n",
    "        self.K = jnp.zeros((self.T, u_dim, x_dim), dtype=float) # dim: T x u_dim x x_dim\n",
    "        # coefficients for the quadratic cost\n",
    "        self.P = jnp.eye(x_dim, x_dim, dtype=float) # dim: x_dim x x_dim\n",
    "        self.P = self.P.at[0, 0].set(10)\n",
    "        self.P = self.P.at[2, 2].set(10)\n",
    "        self.P = self.P.at[4, 4].set(10)\n",
    "        self.R = jnp.eye(u_dim, u_dim, dtype=float)  # dim: u_dim x u_dim\n",
    "\n",
    "\n",
    "        # gym-pybullet-drones environments\n",
    "        # Create an environment\n",
    "        # for initial rollout\n",
    "        env_config = {'info_in_reset': True, \n",
    "                      'ctrl_freq': 60, \n",
    "                      'pyb_freq': 240, \n",
    "                      'physics': 'pyb', \n",
    "                      'gui': False, \n",
    "                      'quad_type': 3, # 3-D \n",
    "                      'normalized_rl_action_space': False, \n",
    "                      'episode_len_sec': duration, \n",
    "                      'init_state': None, \n",
    "                      'randomized_init': False, \n",
    "                      'init_state_randomization_info': None, \n",
    "                      'inertial_prop': None, \n",
    "                      'randomized_inertial_prop': False, \n",
    "                      'inertial_prop_randomization_info': None, \n",
    "                      'task': 'stabilization', \n",
    "                      'task_info': None, \n",
    "                      'cost': 'rl_reward', \n",
    "                      'disturbances': None, \n",
    "                      'adversary_disturbance': None, \n",
    "                      'adversary_disturbance_offset': 0.0, \n",
    "                      'adversary_disturbance_scale': 0.01, \n",
    "                      'constraints': None, \n",
    "                      'done_on_violation': False, \n",
    "                      'use_constraint_penalty': False, \n",
    "                      'constraint_penalty': -1, \n",
    "                      'verbose': False, \n",
    "                      'norm_act_scale': 0.1, \n",
    "                      'obs_goal_horizon': 0, \n",
    "                      'rew_state_weight': 1.0, \n",
    "                      'rew_act_weight': 0.0001, \n",
    "                      'rew_exponential': True, \n",
    "                      'done_on_out_of_bound': True,\n",
    "                      'task_info': {'stabilization_goal': [0, 0, 1],\n",
    "                                    'stabilization_goal_tolerance': 0.0,\n",
    "                                    'proj_point': [0, 0, 0.5], \n",
    "                                    'proj_normal': [0, 1, 1]}}\n",
    "        self.random_env = Quadrotor(**env_config)\n",
    "        self.random_env.seed(0)\n",
    "        init_state, _ = self.random_env.reset()\n",
    "        env_config_static = env_config.copy()\n",
    "        env_config_static['randomized_init'] = False\n",
    "        env_config_static['init_state'] = init_state\n",
    "        env_config_static['gui'] = use_gui\n",
    "        env_config_static_test = env_config_static.copy()\n",
    "        env_config_static_test['gui'] = use_gui\n",
    "        self.static_env = Quadrotor(**env_config_static)\n",
    "        #self.test_env = Quadrotor(**env_config_static_test)\n",
    "\n",
    "        # system parameters\n",
    "        self.M = self.static_env.MASS\n",
    "        self.Iyy = self.static_env.J[1, 1]\n",
    "        self.g = self.static_env.GRAVITY_ACC\n",
    "        self.length = self.static_env.L\n",
    "        self.dt = self.static_env.CTRL_TIMESTEP\n",
    "        self.Ixx = self.static_env.J[0, 0]\n",
    "        self.Izz = self.static_env.J[2, 2]\n",
    "        self.J = jnp.array([[self.Ixx, 0., 0,],\n",
    "                            [0., self.Iyy, 0.],\n",
    "                            [0., 0., self.Izz]], dtype=float)\n",
    "        self.Jinv = jnp.array([[1. / self.Ixx, 0., 0,],\n",
    "                               [0., 1. / self.Iyy, 0.],\n",
    "                               [0., 0., 1. / self.Izz]], dtype=float)\n",
    "        self.gamma = self.static_env.KM / self.static_env.KF\n",
    "\n",
    "        \n",
    "        # goals are in the environment\n",
    "\n",
    "    def rollout_initial(self):\n",
    "        break_counter = 0\n",
    "        self.static_env.seed(0)\n",
    "        observation, _ = self.static_env.reset()\n",
    "        for i in range(self.T * self.control_freq):\n",
    "            self.x = self.x.at[i].set(jnp.array(observation))\n",
    "            observation, reward, terminated, info = self.static_env.step(np.array(self.u[i], dtype=float))\n",
    "            # mbrl cartpole env does not allow further steps after termination\n",
    "            if terminated:\n",
    "                break\n",
    "            break_counter += 1\n",
    "        print('\\trollout_initial break at :', break_counter)\n",
    "        #self.random_env.close()\n",
    "\n",
    "    def update_trajectory(self, mu=1):\n",
    "        observation, _ = self.static_env.reset()\n",
    "        break_counter = 0\n",
    "        for i in range(self.T * self.control_freq):\n",
    "            # state\n",
    "            self.updated_x = self.updated_x.at[i].set(jnp.array(observation, dtype=float))\n",
    "            # new_control = current_control + delta_control,\n",
    "            # where delta_control = k + K @ delta_x\n",
    "            new_control = self.u[i] + mu * self.k[i].ravel() + \\\n",
    "                self.K[i] @ (self.updated_x[i] - self.x[i]).T\n",
    "            # update the current_control with the new_control\n",
    "            self.u = self.u.at[i].set(new_control)\n",
    "            observation, reward, terminated, info = self.static_env.step(np.array(self.u[i], dtype=float))\n",
    "            if terminated:\n",
    "                break\n",
    "            break_counter += 1\n",
    "        print('\\tupdate_trajectory break at :', break_counter)\n",
    "        self.x = self.updated_x.copy()\n",
    "\n",
    "    def get_trajectory_cost_value(self, x, u, P, R):\n",
    "        '''\n",
    "            x: dim of T x x_dim\n",
    "            u: dim of T x u_dim\n",
    "            P: dim of x_dim x x_dim\n",
    "            R: dim of u_dim x u_dim\n",
    "        '''\n",
    "        trajectory_cost = 0\n",
    "        # accumulate over the planning horizon\n",
    "        # except the terminal state\n",
    "        for i in range(self.T - 1):\n",
    "            # quadratic cost\n",
    "            one_step_cost = self.get_trajectory_cost_one_step(x[i], u[i], P, R)\n",
    "            #print('one_step_cost:', one_step_cost)\n",
    "            trajectory_cost += one_step_cost\n",
    "        return trajectory_cost\n",
    "\n",
    "    def get_terminal_cost(self, x_terminal, eta=1):\n",
    "        x_goal = self.static_env.X_GOAL\n",
    "        error = x_terminal - x_goal\n",
    "        penalty = eta * jnp.eye(len(x_terminal), dtype=float)\n",
    "        return error @ penalty @ error.T\n",
    "    \n",
    "    def get_trajectory_cost_one_step(self, x, u, P, R):\n",
    "        '''\n",
    "            x: dim of 1 x x_dim\n",
    "            u: dim of 1 x u_dim\n",
    "            P: dim of x_dim x x_dim\n",
    "            R: dim of u_dim x u_dim\n",
    "        '''\n",
    "        x_goal = self.static_env.X_GOAL\n",
    "        u_goal = self.static_env.U_GOAL\n",
    "        return (x - x_goal) @ P @ (x - x_goal).T + (u - u_goal) @ R @ (u - u_goal).T\n",
    "\n",
    "    # system dynamics\n",
    "    def F(self, \n",
    "          x: jnp.ndarray, \n",
    "          u: jnp.ndarray):\n",
    "        '''\n",
    "            x: \n",
    "                0: x-position\n",
    "                1: x-velocity\n",
    "                2: y-position\n",
    "                3: y-velocity\n",
    "                4: z-position\n",
    "                5: z-velocity\n",
    "                6: x-quaternion\n",
    "                7: y-quaternion\n",
    "                8: z-quaternion\n",
    "                9: x-angular velocity\n",
    "                10: y-angular velocity\n",
    "                11: z-angular velocity\n",
    "            u: \n",
    "                0: thrust\n",
    "                1: x-torque\n",
    "                2: y-torque\n",
    "                3: z-torque\n",
    "        '''\n",
    "        # PyBullet Euler angles use the SDFormat for rotation matrices.\n",
    "        Rob = rotXYZ(x[6], x[7], x[8])  # rotation matrix transforming a vector in the body frame to the world frame.\n",
    "        # From Ch. 2 of Luis, Carlos, and Jérôme Le Ny. 'Design of a trajectory tracking controller for a\n",
    "        # nanoquadcopter.' arXiv preprint arXiv:1608.05786 (2016).\n",
    "\n",
    "        # Defining the dynamics function.\n",
    "        # We are using the velocity of the base wrt to the world frame expressed in the world frame.\n",
    "        # Note that the reference expresses this in the body frame.\n",
    "        oVdot_cg_o = Rob @ jnp.array([0., 0., jnp.sum(u)], dtype=float) / self.M - jnp.array([0., 0., self.g], dtype=float)\n",
    "        pos_ddot = oVdot_cg_o\n",
    "        Mb = jnp.array([self.length / jnp.sqrt(2.) * (u[0] + u[1] - u[2] - u[3]),\n",
    "                        self.length / jnp.sqrt(2.) * (-u[0] + u[1] + u[2] - u[3]),\n",
    "                        self.gamma * (-u[0] + u[1] - u[2] + u[3])], dtype=float).T\n",
    "        rate_dot = self.Jinv @ (Mb - (skew(x[9:].T) @ self.J @ x[9:].T))\n",
    "        ang_dot = jnp.array([[1., jnp.sin(x[6]) * jnp.tan(x[7]), jnp.cos(x[6]) * jnp.tan(x[7])],\n",
    "                             [0., jnp.cos(x[6]), -jnp.sin(x[6])],\n",
    "                             [0., jnp.sin(x[6]) / jnp.cos(x[7]), jnp.cos(x[6]) / jnp.cos(x[7])]]) @ x[9:].T\n",
    "        next_quaternion = x[6:9] + ang_dot * self.dt\n",
    "        next_angular_velocity = x[9:] + rate_dot * self.dt\n",
    "        next_state_pos_vel = jnp.array([x[0] + x[1] * self.dt, \n",
    "                                x[1] + pos_ddot[0] * self.dt, \n",
    "                                x[2] + x[3] * self.dt,\n",
    "                                x[3] + pos_ddot[1] * self.dt, \n",
    "                                x[4] + x[5] * self.dt,\n",
    "                                x[5] + pos_ddot[2] * self.dt,\n",
    "                                ], dtype=float)\n",
    "        next_state = jnp.concatenate((next_state_pos_vel, next_quaternion, next_angular_velocity))\n",
    "        return next_state\n",
    "\n",
    "    def get_cost_derivatives(self, x, u, P, R):\n",
    "        L_x = jax.grad(self.get_trajectory_cost_one_step, argnums=0) \\\n",
    "            (x, u, P, R) # dim: x_dim\n",
    "        L_u = jax.grad(self.get_trajectory_cost_one_step, argnums=1) \\\n",
    "            (x, u, P, R) # dim: u_dim\n",
    "        L_xu = jax.jacfwd(jax.grad(self.get_trajectory_cost_one_step, argnums=0), argnums=1) \\\n",
    "            (x, u, P, R) # dim: x_dim x u_dim\n",
    "        L_ux = jax.jacfwd(jax.grad(self.get_trajectory_cost_one_step, argnums=1), argnums=0) \\\n",
    "            (x, u, P, R) # dim: u_dim x x_dim\n",
    "        L_xx = jax.jacfwd(jax.grad(self.get_trajectory_cost_one_step, argnums=0), argnums=0) \\\n",
    "            (x, u, P, R) # dim: x_dim x x_dim\n",
    "        L_uu = jax.jacfwd(jax.grad(self.get_trajectory_cost_one_step, argnums=1), argnums=1) \\\n",
    "            (x, u, P, R) # dim: u_dim x u_dim\n",
    "        return L_x, L_u, L_xu, L_ux, L_xx, L_uu\n",
    "\n",
    "    def test_render(self, mu=1):\n",
    "        print('testing...')\n",
    "        self.test_env.seed(0)\n",
    "        observation, _ = self.test_env.reset()\n",
    "        for i in range(self.T * self.control_freq):\n",
    "            print('test step:', i)\n",
    "            observation = jnp.array(observation, dtype=float)\n",
    "            # new_control = current_control + delta_control,\n",
    "            # where delta_control = k + K @ delta_x\n",
    "            new_control = self.u[i] + mu * self.k[i].ravel() + \\\n",
    "                self.K[i] @ (observation - self.test_x[i]).T\n",
    "            self.test_x = self.test_x.at[i].set(observation)\n",
    "            # update the current_control with the new_control\n",
    "            self.u = self.u.at[i].set(new_control)\n",
    "            observation, reward, terminated, info = self.test_env.step(np.array(self.u[i], dtype=float))\n",
    "            if terminated:\n",
    "                break\n",
    "            time.sleep(1/240)\n",
    "        self.test_env.close()\n",
    "\n",
    "    def ddp(self):\n",
    "        self.rollout_initial()\n",
    "        for i in range(self.iteration):\n",
    "            t1 = time.time()\n",
    "            cost = self.get_trajectory_cost_value(x=self.x, \n",
    "                                                  u=self.u, \n",
    "                                                  P=self.P, \n",
    "                                                  R=self.R)\n",
    "            cost += self.get_terminal_cost(x_terminal=self.x[-1])\n",
    "            #print('cost.shape:', cost.shape)\n",
    "            print(f'ddp iteration: {i}, initial cost: {cost}')\n",
    "\n",
    "            L_x, L_u, L_xu, L_ux, L_xx, L_uu = self.get_cost_derivatives(self.x[-1], \n",
    "                                                                         self.u[-1], \n",
    "                                                                         self.P, \n",
    "                                                                         self.R)\n",
    "\n",
    "            # get terminal gains\n",
    "            k = -jnp.linalg.inv(L_uu) @ L_u\n",
    "            K = -jnp.linalg.inv(L_uu) @ L_ux\n",
    "\n",
    "            # set gains at the final time step\n",
    "            self.k = self.k.at[-1].set(k) \n",
    "            self.K = self.K.at[-1].set(K)\n",
    "\n",
    "            V_x = jax.grad(self.get_terminal_cost, argnums=0) \\\n",
    "                (self.x[-1]) # dim: x_dim\n",
    "            V_xx = jax.jacfwd(jax.grad(self.get_terminal_cost, argnums=0), argnums=0) \\\n",
    "                (self.x[-1]) # dim: x_dim x x_dim\n",
    "\n",
    "            print('backward pass...')\n",
    "            # propagating backwards to obtain gains over time steps\n",
    "            for j in reversed(range(self.T - 1)):\n",
    "                #print(f'\\tbackward step: {j}')\n",
    "                # get partial derivatives of dynamics\n",
    "                F_x = jax.jacfwd(self.F, argnums=0)(self.x[j], \n",
    "                                                    self.u[j]) # dim: x_dim x x_dim\n",
    "                F_u = jax.jacfwd(self.F, argnums=1)(self.x[j], \n",
    "                                                    self.u[j]) # dim: x_dim x u_dim\n",
    "                F_xx = jax.jacfwd(jax.jacfwd(self.F, argnums=0), argnums=0) \\\n",
    "                    (self.x[j], \n",
    "                     self.u[j]) # dim: x_dim x x_dim x x_dim\n",
    "                F_ux = jax.jacfwd(jax.jacfwd(self.F, argnums=1), argnums=0) \\\n",
    "                    (self.x[j], \n",
    "                     self.u[j]) # dim: x_dim x u_dim x x_dim\n",
    "                F_uu = jax.jacfwd(jax.jacfwd(self.F, argnums=1), argnums=1) \\\n",
    "                    (self.x[j], \n",
    "                     self.u[j]) # dim: x_dim x u_dim x u_dim\n",
    "\n",
    "                # get partial derivatives of instantaneous cost \n",
    "                L_x, L_u, L_xu, L_ux, L_xx, L_uu = self.get_cost_derivatives(self.x[j], \n",
    "                                                                             self.u[j], \n",
    "                                                                             self.P, \n",
    "                                                                             self.R)\n",
    "\n",
    "                # get Q function\n",
    "                Q_x = L_x + V_x @ F_x # dim: x_dim\n",
    "                Q_u = L_u + V_x @ F_u # dim: u_dim\n",
    "                Q_xx = L_xx + F_x.T @ V_xx @ F_x #+ V_x @ F_xx # dim: x_dim x x_dim\n",
    "                Q_ux = L_ux + F_u.T @ V_xx @ F_x #+ jnp.einsum('i, ijk -> jk', V_x, F_ux) # dim: u_dim x x_dim\n",
    "                Q_uu = L_uu + F_u.T @ V_xx @ F_u #+ jnp.einsum('i, ijk -> jk', V_x, F_uu) # dim: u_dim x u_dim\n",
    "\n",
    "                # set gains each time step\n",
    "                k = -jnp.linalg.inv(Q_uu) @ Q_u\n",
    "                K = -jnp.linalg.inv(Q_uu) @ Q_ux\n",
    "                self.k = self.k.at[j].set(k) \n",
    "                self.K = self.K.at[j].set(K)\n",
    "\n",
    "                # compute the partial derivatives of the value function \n",
    "                V_x = Q_x - Q_ux.T @ jnp.linalg.inv(Q_uu) @ Q_u # dim: x_dim\n",
    "                V_xx = Q_xx - Q_ux.T @ jnp.linalg.inv(Q_uu) @ Q_ux # dim: x_dim x x_dim\n",
    "                \n",
    "            self.update_trajectory()\n",
    "            t2 = time.time()\n",
    "            print('elapsed iteration time: ', t2 - t1)\n",
    "            cost = self.get_trajectory_cost_value(x=self.x, \n",
    "                                                  u=self.u, \n",
    "                                                  P=self.P, \n",
    "                                                  R=self.R)\n",
    "            cost += self.get_terminal_cost(x_terminal=self.x[-1])\n",
    "            print(f'ddp iteration: {i}, optimized cost: {cost}')\n",
    "        self.static_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taehy\\anaconda3\\envs\\ddp\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "quadcopter_3d = Quadcopter3D(n_drones=DEFAULT_NUM_DRONES,\n",
    "                             use_gui=DEFAULT_GUI,\n",
    "                             record_video=DEFAULT_RECORD_VISION,\n",
    "                             debug_gui=DEFAULT_USER_DEBUG_GUI,\n",
    "                             simulation_freq=DEFAULT_SIMULATION_FREQ_HZ,\n",
    "                             control_freq=DEFAULT_CONTROL_FREQ_HZ,\n",
    "                             duration=DEFAULT_DURATION_SEC,\n",
    "                             output_folder=DEFAULT_OUTPUT_FOLDER,\n",
    "                             use_colab=DEFAULT_COLAB\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trollout_initial break at : 34\n",
      "ddp iteration: 0, initial cost: 126.8449935913086\n",
      "backward pass...\n",
      "\tupdate_trajectory break at : 74\n",
      "elapsed iteration time:  5.8454649448394775\n",
      "ddp iteration: 0, optimized cost: 116.84886169433594\n",
      "ddp iteration: 1, initial cost: 116.84886169433594\n",
      "backward pass...\n",
      "\tupdate_trajectory break at : 113\n",
      "elapsed iteration time:  5.9968366622924805\n",
      "ddp iteration: 1, optimized cost: 111.21208953857422\n",
      "ddp iteration: 2, initial cost: 111.21208953857422\n",
      "backward pass...\n",
      "\tupdate_trajectory break at : 209\n",
      "elapsed iteration time:  6.861333608627319\n",
      "ddp iteration: 2, optimized cost: 107.96401977539062\n",
      "ddp iteration: 3, initial cost: 107.96401977539062\n",
      "backward pass...\n",
      "\tupdate_trajectory break at : 414\n",
      "elapsed iteration time:  7.831307888031006\n",
      "ddp iteration: 3, optimized cost: 106.5362777709961\n",
      "ddp iteration: 4, initial cost: 106.5362777709961\n",
      "backward pass...\n",
      "\tupdate_trajectory break at : 414\n",
      "elapsed iteration time:  7.813297271728516\n",
      "ddp iteration: 4, optimized cost: 106.29084014892578\n",
      "ddp iteration: 5, initial cost: 106.29084014892578\n",
      "backward pass...\n",
      "\tupdate_trajectory break at : 599\n",
      "elapsed iteration time:  8.849256753921509\n",
      "ddp iteration: 5, optimized cost: 104.47772979736328\n",
      "ddp iteration: 6, initial cost: 104.47772979736328\n",
      "backward pass...\n",
      "\tupdate_trajectory break at : 599\n",
      "elapsed iteration time:  9.905020713806152\n",
      "ddp iteration: 6, optimized cost: 102.8836669921875\n",
      "ddp iteration: 7, initial cost: 102.8836669921875\n",
      "backward pass...\n",
      "\tupdate_trajectory break at : 599\n",
      "elapsed iteration time:  9.857879638671875\n",
      "ddp iteration: 7, optimized cost: 101.28095245361328\n",
      "ddp iteration: 8, initial cost: 101.28095245361328\n",
      "backward pass...\n",
      "\tupdate_trajectory break at : 599\n",
      "elapsed iteration time:  9.71982216835022\n",
      "ddp iteration: 8, optimized cost: 99.75153350830078\n",
      "ddp iteration: 9, initial cost: 99.75153350830078\n",
      "backward pass...\n",
      "\tupdate_trajectory break at : 599\n",
      "elapsed iteration time:  9.935258626937866\n",
      "ddp iteration: 9, optimized cost: 98.35159301757812\n"
     ]
    }
   ],
   "source": [
    "quadcopter_3d.ddp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
